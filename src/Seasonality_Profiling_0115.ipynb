{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# from sklearn.cluster import AffinityPropagation\n",
    "# from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.cluster import MeanShift\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/derekwang/Work/Forecasting/Final_Forecast_Process_0108/Data'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_wd = os.getcwd()\n",
    "data_dir = os.path.join(curr_wd, 'Data')\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (0,1,2,3,4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12649941\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Store</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>247</td>\n",
       "      <td>271</td>\n",
       "      <td>201450</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>237</td>\n",
       "      <td>351</td>\n",
       "      <td>201528</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>246</td>\n",
       "      <td>473</td>\n",
       "      <td>201625</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>263</td>\n",
       "      <td>261</td>\n",
       "      <td>201510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>249</td>\n",
       "      <td>484</td>\n",
       "      <td>201620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subclass  SKU Store    WEEK Units\n",
       "0       12  247   271  201450     2\n",
       "1       12  237   351  201528     1\n",
       "2       12  246   473  201625     1\n",
       "3       12  263   261  201510     0\n",
       "4       12  249   484  201620     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_raw_dir = os.path.join(data_dir, '3yearsSales.txt')\n",
    "demand_raw_df = pd.read_csv(demand_raw_dir, sep = '\\t', header=0)\n",
    "print (np.size(demand_raw_df, 0))\n",
    "demand_raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Store</th>\n",
       "      <th>Week</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>215</td>\n",
       "      <td>413</td>\n",
       "      <td>201703</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>174</td>\n",
       "      <td>324</td>\n",
       "      <td>201701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>213</td>\n",
       "      <td>201702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>242</td>\n",
       "      <td>201701</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>107</td>\n",
       "      <td>201701</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subclass  SKU  Store    Week  Units\n",
       "0         6  215    413  201703    0.0\n",
       "1         6  174    324  201701    0.0\n",
       "2         2  133    213  201702    0.0\n",
       "3         5  194    242  201701    0.0\n",
       "4         4   24    107  201701   97.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_raw_demand_dir = os.path.join(data_dir, 'Week1_4.txt')\n",
    "add_raw_demand_df = pd.read_csv(add_raw_demand_dir, sep='\\t', header=0)\n",
    "add_raw_demand_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SKU</th>\n",
       "      <th>Store</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>102</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>103</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>105</td>\n",
       "      <td>31.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SKU  Store     1     2     3     4\n",
       "0    6    101  11.0  20.0  14.0  10.0\n",
       "1    6    102  20.0   2.0   9.0   4.0\n",
       "2    6    103  10.0   5.0  17.0  15.0\n",
       "3    6    104  15.0  12.0  12.0   3.0\n",
       "4    6    105  31.0  71.0  16.0  19.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_add = add_raw_demand_df.sort_values(['Subclass', 'SKU', 'Store', 'Week'])\n",
    "LIST = format_add.loc[:, ['SKU', 'Store']].drop_duplicates().copy().reset_index(drop=True)\n",
    "\n",
    "add_sales = format_add[(format_add.Week >= 201701)]['Units'].values.reshape(-1,add_raw_demand_df.Week.nunique())\n",
    "add_sales_df = pd.DataFrame(add_sales, columns = [i for i in range(1, add_raw_demand_df.Week.nunique()+1)])\n",
    "\n",
    "add_df = pd.concat([LIST, add_sales_df], axis = 1)\n",
    "add_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 3734257 into shape (52)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c11d0c2f4ee6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mSTR_SKU_LIST\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'SKU'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Store'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msales_2014\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeek\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m201501\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Units'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msales_2015\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeek\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m201452\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeek\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m201601\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Units'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msales_2016\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeek\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m201552\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mformat_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWeek\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m201701\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Units'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m52\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 3734257 into shape (52)"
     ]
    }
   ],
   "source": [
    "format_df = demand_raw_df.sort_values(['Subclass', 'SKU', 'Store', 'Week'])\n",
    "STR_SKU_LIST = format_df.loc[:, ['Subclass','SKU', 'Store']].drop_duplicates().copy().reset_index(drop=True)\n",
    "\n",
    "sales_2014 = format_df[(format_df.Week < 201501)]['Units'].values.reshape(-1,52)\n",
    "sales_2015 = format_df[(format_df.Week > 201452) & (format_df.Week < 201601)]['Units'].values.reshape(-1,52)\n",
    "sales_2016 = format_df[(format_df.Week > 201552) & (format_df.Week < 201701)]['Units'].values.reshape(-1,52)\n",
    "\n",
    "two_years_mean = (sales_2014 + sales_2015) / 2\n",
    "three_years_mean = (sales_2014 + sales_2015 + sales_2016) / 3\n",
    "\n",
    "df_2Years = pd.DataFrame(two_years_mean, columns = [i for i in range(1,53)])\n",
    "df_3Years = pd.DataFrame(three_years_mean, columns = [i for i in range(1,53)])\n",
    "\n",
    "df_Year1 = pd.DataFrame(sales_2014, columns = [i for i in range(1,53)])\n",
    "df_Year2 = pd.DataFrame(sales_2015, columns = [i for i in range(1,53)])\n",
    "df_Year3 = pd.DataFrame(sales_2016, columns = [i for i in range(1,53)])\n",
    "\n",
    "two_years_mean_df = pd.concat([STR_SKU_LIST, df_2Years], axis = 1)\n",
    "three_years_mean_df = pd.concat([STR_SKU_LIST, df_3Years], axis = 1)\n",
    "year1_df = pd.concat([STR_SKU_LIST, df_Year1], axis = 1)\n",
    "year2_df = pd.concat([STR_SKU_LIST, df_Year2], axis = 1)\n",
    "year3_df = pd.concat([STR_SKU_LIST, df_Year3], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_df = demand_raw_df.sort_values(['Subclass', 'SKU', 'Store'])\n",
    "STR_SKU_LIST = format_df.loc[:, ['Subclass','SKU', 'Store']].drop_duplicates().copy().reset_index(drop=True)\n",
    "\n",
    "week_list_c = [i for i in range(201401, 201453)]\n",
    "week_list_c.extend([i for i in range(201501, 201553)])\n",
    "week_list_c.extend([i for i in range(201601, 201653)])\n",
    "week_list_unique = pd.DataFrame(week_list_c, columns=['WEEK'])\n",
    "week_list = week_list_unique.copy().append([week_list_unique] * (np.size(STR_SKU_LIST, 0)-1))\n",
    "\n",
    "l = STR_SKU_LIST.copy().append([STR_SKU_LIST] * (np.size(week_list_unique, 0)-1)).sort_values(['Subclass','SKU', 'Store']).reset_index(drop=True)\n",
    "\n",
    "header_values = np.concatenate((l.values, week_list.values), axis = 1)\n",
    "headers_df = pd.DataFrame(header_values, columns = ['Subclass', 'SKU', 'Store', 'WEEK'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Store</th>\n",
       "      <th>WEEK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subclass SKU Store    WEEK\n",
       "0        1   6   101  201401\n",
       "1        1   6   101  201402\n",
       "2        1   6   101  201403\n",
       "3        1   6   101  201404\n",
       "4        1   6   101  201405"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subclass</th>\n",
       "      <th>SKU</th>\n",
       "      <th>Store</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201401</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201402</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201403</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201404</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>101</td>\n",
       "      <td>201405</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subclass SKU Store    WEEK Units\n",
       "0        1   6   101  201401    25\n",
       "1        1   6   101  201402     2\n",
       "2        1   6   101  201403     5\n",
       "3        1   6   101  201404    12\n",
       "4        1   6   101  201405    15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_with_Nan = pd.merge(headers_df, demand_raw_df, how='left', on=['Subclass', 'SKU', 'Store', 'WEEK'])\n",
    "demand_with_Nan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subclass    False\n",
       "SKU          True\n",
       "Store        True\n",
       "WEEK        False\n",
       "Units        True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demand_with_Nan.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Functions:\n",
    "\n",
    "def calc_ncq(df):\n",
    "    ncq_df = df.iloc[:,2:54].cumsum(axis = 1)\n",
    "    ncq_max = ncq_df.iloc[:,-1]\n",
    "    ncq_out =  ncq_df.values /  ncq_max.values[:,None]\n",
    "    out_df = df.copy()\n",
    "    out_df.iloc[:,2:54] = ncq_out\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "def scal_qty(df):\n",
    "    scal_df = df.iloc[:,2:54].copy()\n",
    "    scal_mean = scal_df.mean(axis = 1)\n",
    "    scal_out =  scal_df.values /  scal_mean.values[:,None]\n",
    "    out_df = df.copy()\n",
    "    out_df.iloc[:,2:54] = scal_out\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "def get_km_result_df(data_ncq, data_scal, kmeans):\n",
    "    title_df = data_ncq.loc[:,['SKU', 'Store']]\n",
    "    title_df['Class_label'] = kmeans.labels_\n",
    "    scal_df = title_df.merge(data_scal, how = 'left', on =['SKU', 'Store'])\n",
    "    centers_df = scal_df.iloc[:,2:].groupby('Class_label').mean().copy()\n",
    "    centers_df.reset_index(inplace=True)\n",
    "    kmean_result_df = title_df.merge(centers_df, how = 'left', on =['Class_label'])\n",
    "    \n",
    "    return kmean_result_df\n",
    "\n",
    "def scal_error_est(km_result, year3_df):\n",
    "    year3_scal = scal_qty(year3_df)\n",
    "    compare = km_result.merge(year3_scal, how = 'left', on =['SKU', 'Store'])\n",
    "    error_matrix = compare.iloc[:,3:55].values - compare.iloc[:,55:107].values\n",
    "    \n",
    "    squared_error = np.sum(np.square(error_matrix))\n",
    "    return squared_error\n",
    "\n",
    "def ncq_error_est(km_result, year3_df):\n",
    "    year3_scal = calc_ncq(year3_df)\n",
    "    km = calc_ncq(km_result.drop(['Class_label'], axis = 1))\n",
    "    compare = km.merge(year3_scal, how = 'left', on =['SKU', 'Store'])\n",
    "    error_matrix = compare.iloc[:,2:54].values - compare.iloc[:,54:106].values\n",
    "    \n",
    "    squared_error = np.sum(np.square(error_matrix))\n",
    "    return squared_error\n",
    "\n",
    "def get_Kmeans_fcst(base_df, factors_df):\n",
    "    merge = pd.merge(base_df, factors_df.drop(['Class_label'], axis=1), how='inner', on=['SKU', 'Store'])\n",
    "    matrix_base = merge.iloc[:,2:54].values\n",
    "    matrix_factors = merge.iloc[:,54:106].values\n",
    "    matrix_fcst = matrix_base*matrix_factors\n",
    "    fcst_df = pd.DataFrame(matrix_fcst, columns=['Wk%d' % i for i in range(1,53)])\n",
    "    result = pd.concat([merge.loc[:,['SKU','Store']], fcst_df], axis =1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Try to find the best K\n",
    "\n",
    "#drop rows with any 'null' value \n",
    "#drop rows with sum of all sales equal to zero\n",
    "data_clean = two_years_mean_df.dropna(axis = 0, how = 'any')\n",
    "data_clean = data_clean[(data_clean.iloc[:,2:54].sum(axis =1) > 0)]\n",
    "\n",
    "#smooth raw demand using exponential weighted moving average\n",
    "data_ewma = data_clean.copy()\n",
    "data_ewma.iloc[:,2:54] = data_clean.iloc[:,2:54].ewm(span = 4, axis = 1).mean()\n",
    "print('Count of Store_SKU in ewma: %d' % np.size(data_ewma, 0))\n",
    "\n",
    "#set threshhold for sales volume, item will be grouped together when annully sales <= 52\n",
    "data_slow_mover = data_ewma[(data_ewma.iloc[:,2:54].sum(axis =1) <= 52)]\n",
    "data_slow_mover = data_slow_mover.iloc[:, 0:54]\n",
    "print ('Count of Store_SKU in slow_mover: %d' % np.size(data_slow_mover, 0))\n",
    "\n",
    "#set threshhold for sales volume, item can be processed when annully sales > 52\n",
    "data_vol = data_ewma[(data_ewma.iloc[:,2:54].sum(axis =1) > 52)]\n",
    "print ('Count of Store_SKU to be processed: %d' % np.size(data_vol, 0))\n",
    "\n",
    "\n",
    "data_ncq = calc_ncq(data_vol)\n",
    "data_scal = scal_qty(data_vol)\n",
    "\n",
    "\n",
    "#Finding best K for target dataset\n",
    "test_list =[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "squared_error = []\n",
    "for i in test_list:\n",
    "    print (str(datetime.datetime.now()))\n",
    "    X_train = data_ncq.iloc[:,2:54].values\n",
    "    kmeans = KMeans(n_clusters = i, random_state=0).fit(X_train)\n",
    "    error = ncq_error_est(get_km_result_df(data_ncq, data_scal, kmeans), year3_df)\n",
    "    squared_error.append(error)\n",
    "    print (str(datetime.datetime.now()))\n",
    "    print (\"Error for %d is: %s\" % (i, error))\n",
    "\n",
    "print(squared_error)\n",
    "\n",
    "\n",
    "plt.plot(test_list, squared_error)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_k = test_list[squared_error.index(min(squared_error))]\n",
    "final_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final run with best k\n",
    "\n",
    "\n",
    "#drop rows with any 'null' value \n",
    "#drop rows with sum of all sales equal to zero\n",
    "data_clean = three_years_mean_df.dropna(axis = 0, how = 'any')\n",
    "data_clean = data_clean[(data_clean.iloc[:,2:54].sum(axis =1) > 0)]\n",
    "\n",
    "#smooth raw demand using exponential weighted moving average\n",
    "data_ewma = data_clean.copy()\n",
    "data_ewma.iloc[:,2:54] = data_clean.iloc[:,2:54].ewm(span = 4, axis = 1).mean()\n",
    "print('Count of Store_SKU in ewma: %d' % np.size(data_ewma, 0))\n",
    "\n",
    "#set threshhold for sales volume, item will be grouped together when annully sales <= 52\n",
    "data_slow_mover = data_ewma[(data_ewma.iloc[:,2:54].sum(axis =1) <= 52)]\n",
    "data_slow_mover = data_slow_mover.iloc[:, 0:54]\n",
    "print ('Count of Store_SKU in slow_mover: %d' % np.size(data_slow_mover, 0))\n",
    "\n",
    "#set threshhold for sales volume, item can be processed when annully sales > 52\n",
    "data_vol = data_ewma[(data_ewma.iloc[:,2:54].sum(axis =1) > 52)]\n",
    "print ('Count of Store_SKU to be processed: %d' % np.size(data_vol, 0))\n",
    "\n",
    "\n",
    "data_ncq = calc_ncq(data_vol)\n",
    "data_scal = scal_qty(data_vol)\n",
    "\n",
    "\n",
    "print (str(datetime.datetime.now()))\n",
    "X_train = data_ncq.iloc[:,2:54].values\n",
    "kmeans = KMeans(n_clusters = final_k, random_state=0).fit(X_train)\n",
    "\n",
    "pieces = []\n",
    "\n",
    "#get the result from Kmeans\n",
    "kmeans_result = get_km_result_df(data_ncq, data_scal, kmeans)\n",
    "pieces.append(kmeans_result)\n",
    "\n",
    "\n",
    "#get labels for slow movers\n",
    "scal_slow_mover = scal_qty(data_slow_mover)\n",
    "scal_slow_mover['Class_label'] = np.array([9999]*np.size(scal_slow_mover, 0))\n",
    "slow_mover_centers = scal_slow_mover.iloc[:,2:].groupby('Class_label').mean()\n",
    "slow_mover_centers.reset_index(inplace=True)\n",
    "slow_mover_result = scal_slow_mover.loc[:,['SKU', 'Store', 'Class_label']].merge(slow_mover_centers, how='left', on=['Class_label'])\n",
    "\n",
    "pieces.append(slow_mover_result)\n",
    "\n",
    "df_result = pd.concat(pieces)\n",
    "df_result['SKU'] = df_result['SKU'].astype('object')\n",
    "df_result['Store'] = df_result['Store'].astype('object')\n",
    "\n",
    "print (str(datetime.datetime.now()))\n",
    "\n",
    "df_result.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#export seasonal factors at str_sku level\n",
    "df_export = df_result.copy()\n",
    "df_export.to_csv(os.path.join(data_dir, 'Output/sample_Seasonalities_0109.csv'))\n",
    "df_export.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = df_export[(df_export.SKU == 999) & (df_export.Store == 102)].iloc[:,3:].values\n",
    "plt.plot(a[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get ARIMA output\n",
    "\n",
    "ARIMA_dir = os.path.join(data_dir, 'fake_ARIMA_0109.txt')\n",
    "ARIMA_df_raw = pd.read_csv(ARIMA_dir, sep = ',', header = 0, index_col=0).sort_values(by=['SKU', 'Store', 'Week'])\n",
    "ARIMA_df_raw.reset_index(drop=True)\n",
    "STR_SKU_LIST = ARIMA_df_raw.loc[:, ['SKU', 'Store']].drop_duplicates().copy().reset_index(drop=True)\n",
    "\n",
    "ARIMA_output = ARIMA_df_raw['Units'].values.reshape(-1,52)\n",
    "ARIMA_h = pd.DataFrame(ARIMA_output, columns = [i for i in range(1,53)])\n",
    "ARIMA_df = pd.concat([STR_SKU_LIST, ARIMA_h], axis=1)\n",
    "ARIMA_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmean_fcst = get_Kmeans_fcst(ARIMA_df, df_result)\n",
    "# kmean_fcst.to_csv(os.path.join(data_dir, 'Output/final_forecast_0109.csv'))\n",
    "kmean_fcst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sls(df, *num_plot):\n",
    "    if not num_plot:\n",
    "        for i in range(np.size(df, 0)):\n",
    "            plt.plot(df.iloc[i, 2:].values)\n",
    "    else:\n",
    "        rand_int = np.random.randint(0, np.size(df, 0), num_plot[0])\n",
    "        plot_df = df.iloc[rand_int, :]\n",
    "        plot_data = plot_df.iloc[:, 2:]\n",
    "        item_loc = plot_df.iloc[:,0:2]\n",
    "\n",
    "        for i in range(num_plot[0]):\n",
    "            plt.plot(plot_data.iloc[i].values)\n",
    "    \n",
    "    ticks = np.arange(0, 52, 5)\n",
    "    labels = np.arange(1, 53, 5)\n",
    "    plt.xticks(ticks, labels)\n",
    "    print (item_loc)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_sales_fcst(SKU, Store):\n",
    "    sales_2014 = year1_df[(year1_df.SKU == SKU) & (year1_df.Store == Store)].iloc[:,2:]\n",
    "    sales_2015 = year2_df[(year2_df.SKU == SKU) & (year2_df.Store == Store)].iloc[:,2:]\n",
    "    sales_2016 = year3_df[(year3_df.SKU == SKU) & (year3_df.Store == Store)].iloc[:,2:]\n",
    "    fcst = kmean_fcst[(kmean_fcst.SKU == SKU) & (kmean_fcst.Store == Store)].iloc[:,2:]\n",
    "    \n",
    "    plt.figure(figsize=(12, 9))\n",
    "    sales2014, = plt.plot(sales_2014.iloc[0].values, label = 'sales2014')\n",
    "    sales2015, = plt.plot(sales_2015.iloc[0].values, label = 'sales2015')\n",
    "    sales2016, = plt.plot(sales_2016.iloc[0].values, label = 'sales2016')\n",
    "    fcst, = plt.plot(fcst.iloc[0].values, label = 'fcst')\n",
    "    ticks = np.arange(0, 52, 5)\n",
    "    labels = np.arange(1, 53, 5)\n",
    "    plt.xticks(ticks, labels)\n",
    "    plt.legend(handles=[sales2014, sales2015, sales2016, fcst])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot sales hist and fcst for a SKU, Store\n",
    "plot_sales_fcst(999, 109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_sls(kmean_fcst,2)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
